version: '3.4'

#### services and ports
## redis_cache: 6379
## mssql: 1433
## mongo: 17017
## loki: 3100
## grafana: 3000
## otel-collector: 4317
## tempo: 4417
## prometheus: 9090
## kafka_b: 9092, 9094
## kafka-ui: 9095
## rest-proxy: 8082
## schema-registry: 8081
## account: 8060
## audit: 8062
## bff: 8063
## census: 8064
## dataacquisition: 8065
## demo-app: 8066
## measureeval: 8067
## normalization: 8068
## notification: 8069
## querydispatch: 8071
## report: 8072
## submission: 8073
## tenant: 8074
## validation: 8075

services:
      
  ###########################################
  ### Redis Cache
  ###########################################

  redis_cache:
    image: redis:6.2-alpine
    restart: always
    ports:
      - '6379:6379'
    container_name: redis
    command: redis-server --save 20 1 --loglevel warning --requirepass ${REDIS_PASS}
    volumes: 
      - redis_cache:/data
    networks:
      - link-nw
      
  ###########################################
  ### Databases
  ###########################################
  
  mssql:
    image: mcr.microsoft.com/mssql/server:2019-latest
    environment:
      - ACCEPT_EULA=Y
      - SA_PASSWORD=${LINK_DB_PASS}
      - MSSQL_PID=Developer
    ports:
      - 1433:1433
    container_name: sql-server
    volumes:
      - mssql_data:/var/opt/mssql
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "/opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P ${LINK_DB_PASS} -Q 'SELECT 1' || exit 1"]
      interval: 10s
      retries: 10
      start_period: 10s
      timeout: 3s
    networks:
      - link-nw
      
  mssql_init:
    image: mcr.microsoft.com/mssql-tools
    container_name: sql-init
    environment:
      LINK_DB_PASS: ${LINK_DB_PASS}
    volumes:
      - type: bind
        source: create-dbs.sql
        target: /create-dbs.sql
    command: bash -c "/opt/mssql-tools/bin/sqlcmd -S mssql -U sa -P ${LINK_DB_PASS} -i /create-dbs.sql"
    depends_on:
      mssql:
        condition: service_healthy
    networks:
      - link-nw
      
  mongo:
    image: mongo:6-jammy
    ports:
      - '17017:27017'
    container_name: mongo
    volumes:
      - mongo_data:/data/db
    networks:
      - link-nw
      
  ###########################################
  ### Telemetry
  ###########################################
      
  loki:
    image: grafana/loki:2.9.0
    ports:
      - "3100:3100"
    container_name: loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - link-nw
      
  otel-collector:
    image: otel/opentelemetry-collector:0.88.0
    container_name: open-telemetry-collector
    restart: always
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./docker-compose.collector.yml:/etc/otel-collector-config.yaml
    ports:
      - "1888:1888"   # pprof extension
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "4317:4317"   # OTLP gRPC receiver
      - "55679:55679" # zpages extension
    networks:
      - link-nw
      
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    container_name: prometheus
    volumes:
      - ./docker-compose.prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    networks:
      - link-nw
    depends_on:
      - otel-collector

  tempo:
    image: grafana/tempo:latest
    command: [ "-config.file=/etc/tempo.yaml" ]
    container_name: tempo
    hostname: tempo
    volumes:
      - ./docker-compose.tempo.yml:/etc/tempo.yaml
    ports:
      - "3200:3200"
      - "4417:4417"
    healthcheck:
      interval: 5s
      retries: 10
      test: wget --no-verbose --tries=1 --spider http://localhost:3200/status || exit 1
    networks:
      - link-nw

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    container_name: grafana
    environment:
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    volumes:
      - ./docker-compose.grafana.yml:/etc/grafana/provisioning/datasources/ds.yaml
    networks:
      - link-nw
      
  ###########################################
  ### KAFKA
  ###########################################
  
  kafka_b:
     image: bitnami/kafka:3.4
     ports:
       - "9092:9092"
       - "9094:9094"
     container_name: kafka-broker
     volumes:
       - kafka_data:/bitnami
       - ./kafka-client.properties:/etc/kafka-client.properties
     environment:
       - KAFKA_BROKER_ID=1
       - KAFKA_CFG_NODE_ID=1
       - KAFKA_CFG_PROCESS_ROLES=broker,controller
       - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@127.0.0.1:9093 
       - KAFKA_CFG_LISTENERS=SASL_PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
       - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:SASL_PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXT
       - KAFKA_CFG_ADVERTISED_LISTENERS=SASL_PLAINTEXT://127.0.0.1:9092,EXTERNAL://kafka_b:9094
       - KAFKA_CLIENT_USERS=${KAFKA_SASL_CLIENT_USER}
       - KAFKA_CLIENT_PASSWORDS=${KAFKA_SASL_CLIENT_PASSWORD}
       - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=SASL_PLAINTEXT
       - KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL=PLAIN
       - KAFKA_INTER_BROKER_USER=controller_user
       - KAFKA_INTER_BROKER_PASSWORD=controller_password
       - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
       - KAFKA_CFG_SASL_MECHANISM_CONTROLLER_PROTOCOL=PLAIN
       - KAFKA_CONTROLLER_USER=${KAFKA_INTER_BROKER_USER}
       - KAFKA_CONTROLLER_PASSWORD=${KAFKA_INTER_BROKER_PASSWORD}
       - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
       - KAFKA_CFG_NUM_PARTITIONS=2
     networks:
       - link-nw
     healthcheck:
      test: [ "CMD-SHELL", "kafka-topics.sh --bootstrap-server kafka:9092 --command-config /etc/kafka-client.properties --list" ]
      interval: 5s
      timeout: 10s
      retries: 5
     
  kafka_init:
    image: confluentinc/cp-kafka:6.1.1
    container_name: kafka-init
    volumes:
      - ./kafka-client.properties:/etc/kafka-client.properties
    depends_on:
      - kafka_b
    entrypoint: [ '/bin/sh', '-c' ]
    networks:
      - link-nw
    command: |
      "
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ReportScheduled --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ReportScheduled-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ReportScheduled-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic RetentionCheckScheduled --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic RetentionCheckScheduled-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic RetentionCheckScheduled-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic PatientCensusScheduled --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic PatientCensusScheduled-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic PatientCensusScheduled-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic PatientEvent --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic PatientEvent-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic PatientEvent-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic DataAcquisitionRequested --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic DataAcquisitionRequested-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic DataAcquisitionRequested-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic PatientIDsAcquired --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic PatientIDsAcquired-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic PatientIDsAcquired-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ResourceAcquired --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ResourceAcquired-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ResourceAcquired-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ResourceNormalized --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ResourceNormalized-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ResourceNormalized-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ResourceEvaluated --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ResourceEvaluated-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ResourceEvaluated-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic SubmitReport --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic SubmitReport-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic SubmitReport-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ReportSubmitted --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ReportSubmitted-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic ReportSubmitted-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic NotificationRequested --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic NotificationRequested-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic NotificationRequested-Retry --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic AuditableEventOccurred --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic AuditableEventOccurred-Error --replication-factor 1 --partitions 1
        kafka-topics --bootstrap-server kafka_b:9094 --command-config /etc/kafka-client.properties --create --if-not-exists --topic AuditableEventOccurred-Retry --replication-factor 1 --partitions 1
      "
      
  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 9095:8080
    depends_on:
      - kafka_b
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka_b:9094
      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: SASL_PLAINTEXT
      KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM: PLAIN
      KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_CLIENT_USER}" password="${KAFKA_SASL_CLIENT_PASSWORD}";'
    networks:
      - link-nw

  rest-proxy:
    image: confluentinc/cp-kafka-rest:latest
    depends_on:
      - kafka_b
    ports:
      - 8082:8082
    container_name: kafka-rest-proxy
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'kafka_b:9094'
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_CLIENT_SECURITY_PROTOCOL: SASL_PLAINTEXT
      KAFKA_REST_CLIENT_SASL_MECHANISM: PLAIN
      KAFKA_REST_CLIENT_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_CLIENT_USER}" password="${KAFKA_SASL_CLIENT_PASSWORD}";'
    networks:
      - link-nw

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    depends_on:
      - kafka_b
    ports:
      - "8081:8081"
    container_name: kafka-schema-registry
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: SASL_PLAINTEXT://kafka_b:9094,PLAINTEXT_INTERNAL://localhost:29092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: SASL_PLAINTEXT
      SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: PLAIN 
      SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_CLIENT_USER}" password="${KAFKA_SASL_CLIENT_PASSWORD}";'
    networks:
      - link-nw
     
  ###########################################
  ### LINK
  ###########################################

  account:
    image: link-account
    container_name: link-account
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      ServiceInformation__Name: Link Account Service
      ServiceInformation__Version: 1.1.00-dev
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      DatabaseProvider: SqlServer
      AutoMigrate: true
      ConnectionStrings__DatabaseConnection: Server=tcp:mssql,1433;Initial Catalog=link-account;Persist Security Info=False;User ID=sa;Password=${LINK_DB_PASS};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;
      ConnectionStrings__Redis: redis_cache:6379
      Cache__Enabled: true
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      ServiceRegistry: "{}"
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
      EnableSwagger: true
      Authentication__EnableAnonymousAccess: true
      SecretManagement__Enabled: false
      SecretManagement__Manager:
      SecretManagement__ManagerUri:
    ports:
      - "8060:8060"
    build:
      context: .
      dockerfile: DotNet/Account/Dockerfile
    networks:
      - link-nw
    depends_on:
      - loki
      - otel-collector
      - kafka_init
      - mssql_init

  audit:
    image: link-audit
    container_name: link-audit
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      ServiceInformation__Name: Link Audit Service
      ServiceInformation__Version: 1.1.00-dev
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      DatabaseProvider: SqlServer
      AutoMigrate: true
      ConnectionStrings__DatabaseConnection: Server=tcp:mssql,1433;Initial Catalog=link-audit;Persist Security Info=False;User ID=sa;Password=${LINK_DB_PASS};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
      EnableSwagger: true
      Authentication__EnableAnonymousAccess: true
    ports:
      - "8062:8062"
    build:
      context: .
      dockerfile: DotNet/Audit/Dockerfile
    networks:
      - link-nw
    depends_on:
      - loki
      - otel-collector
      - kafka_init
      - mssql_init
      
  bff:
    image: link-bff
    container_name: link-bff
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      ConnectionStrings__Redis: redis_cache:6379
      Cache__Enabled: true
      EnableIntegrationFeature: true
      ProblemDetails__IncludeExceptionDetails: false
      LinkTokenService__EnableTokenGenerationEndpoint: false
      LinkTokenService__Authority: placeholder      
      LinkTokenService__LinkAdminEmail:      
      LinkTokenService__TokenLifeSpan: 10    
      Authentication__EnableAnonymousAccess: true
      ServiceRegistry__TenantService__TenantServiceURL: http://tenant:8074
      ServiceRegistry__AccountServiceUrl: http://account:8060
      ServiceRegistry__AuditServiceUrl: http://audit:8062
      ServiceRegistry__CensusServiceUrl: http://census:8064
      ServiceRegistry__DataAcquisitionServiceUrl: http://dataacquisition:8065
      ServiceRegistry__MeasureServiceUrl: http://measureeval:8067
      ServiceRegistry__NormalizationServiceUrl: http://normalization:8068
      ServiceRegistry__NotificationServiceUrl: http://notification:8069
      ServiceRegistry__ReportServiceUrl: http://report:8072
      ServiceRegistry__SubmissionServiceUrl: http://submission:8073
      ServiceRegistry__QueryDispatchServiceUrl: http://querydispatch:8071
      ReverseProxy__Routes__route1__ClusterId: AccountService
      ReverseProxy__Routes__route1__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route1__Match__Path: api/account/{**catch-all}
      ReverseProxy__Routes__route2__ClusterId: AuditService
      ReverseProxy__Routes__route2__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route2__Match__Path: api/audit/{**catch-all}
      ReverseProxy__Routes__route3__ClusterId: CensusService
      ReverseProxy__Routes__route3__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route3__Match__Path: api/census/{**catch-all}
      ReverseProxy__Routes__route4__ClusterId: DataAcquisitionService
      ReverseProxy__Routes__route4__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route4__Match__Path: api/data/{**catch-all}
      ReverseProxy__Routes__route5__ClusterId: MeasureEvaluationService
      ReverseProxy__Routes__route5__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route5__Match__Path: api/measure-definition/{**catch-all}
      ReverseProxy__Routes__route6__ClusterId: NormalizationService
      ReverseProxy__Routes__route6__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route6__Match__Path: api/normalization/{**catch-all}
      ReverseProxy__Routes__route7__ClusterId: NotificationService
      ReverseProxy__Routes__route7__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route7__Match__Path: api/notification/{**catch-all}
      ReverseProxy__Routes__route8__ClusterId: ReportService
      ReverseProxy__Routes__route8__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route8__Match__Path: api/report/{**catch-all}
      ReverseProxy__Routes__route9__ClusterId: ReportService
      ReverseProxy__Routes__route9__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route9__Match__Path: api/reportconfig/{**catch-all}
      ReverseProxy__Routes__route10__ClusterId: TenantService
      ReverseProxy__Routes__route10__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route10__Match__Path: api/facility/{**catch-all}
      ReverseProxy__Routes__route11__ClusterId: QueryDispatchService
      ReverseProxy__Routes__route11__AuthorizationPolicy: AuthenticatedUser
      ReverseProxy__Routes__route11__Match__Path: api/querydispatch/{**catch-all}
      ReverseProxy__Clusters__AccountService__Destinations__destination1__Address: http://account:8060
      ReverseProxy__Clusters__AuditService__Destinations__destination1__Address: http://audit:8062
      ReverseProxy__Clusters__CensusService__Destinations__destination1__Address: http://census:8064
      ReverseProxy__Clusters__DataAcquisitionService__Destinations__destination1__Address: http://dataacquisition:8065
      ReverseProxy__Clusters__MeasureEvaluationService__Destinations__destination1__Address: http://measureeval:8067
      ReverseProxy__Clusters__NormalizationService__Destinations__destination1__Address: http://normalization:8068
      ReverseProxy__Clusters__NotificationService__Destinations__destination1__Address: http://notification:8069
      ReverseProxy__Clusters__ReportService__Destinations__destination1__Address: http://report:8072
      ReverseProxy__Clusters__TenantService__Destinations__destination1__Address: http://tenant:8074
      ReverseProxy__Clusters__QueryDispatchService__Destinations__destination1__Address: http://querydispatch:8071
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
    ports:
      - "8063:8063"
    build:
      context: .
      dockerfile: DotNet/LinkAdmin.BFF/Dockerfile
    networks:
      - link-nw
    depends_on:
      - kafka_init
      - otel-collector
      - redis_cache
      - account
      - audit
      - census
      - dataacquisition
      - measureeval
      - normalization
      - notification
      - report
      - submission
      - tenant
  
  census:
    image: link-census
    container_name: link-census
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      ServiceInformation__Name: Link Census Service
      ServiceInformation__Version: 1.1.00-dev
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      DatabaseProvider: SqlServer
      AutoMigrate: true
      ConnectionStrings__DatabaseConnection: Server=tcp:mssql,1433;Initial Catalog=link-census;Persist Security Info=False;User ID=sa;Password=${LINK_DB_PASS};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
      ServiceRegistry__TenantService__TenantServiceURL: http://tenant:8074
      ServiceRegistry__TenantService__CheckIfTenantExists: false
      ServiceRegistry__TenantService__GetTenantRelativeEndpoint: facility/
      EnableSwagger: true
      Authentication__EnableAnonymousAccess: true      
    ports:
      - "8064:8064"
    build:
      context: .
      dockerfile: DotNet/Census/Dockerfile
    networks:
      - link-nw
    depends_on:
      - loki
      - kafka_init
      - otel-collector
      - mssql_init
      - tenant

  dataacquisition:
    image: link-dataacquisition
    container_name: link-dataacquisition
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      ServiceInformation__Name: Link Data Acquisition Service
      ServiceInformation__Version: 1.1.00-dev
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      DatabaseProvider: SqlServer      
      AutoMigrate: true
      ConnectionStrings__DatabaseConnection: Server=tcp:mssql,1433;Initial Catalog=link-dataacquisition;Persist Security Info=False;User ID=sa;Password=${LINK_DB_PASS};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
      ServiceRegistry__TenantService__TenantServiceURL: http://tenant:8074
      ServiceRegistry__TenantService__CheckIfTenantExists: false
      ServiceRegistry__TenantService__GetTenantRelativeEndpoint: facility/
      EnableSwagger: true
      Authentication__EnableAnonymousAccess: true
    ports:
      - "8065:8065"
    build:
      context: .
      dockerfile: DotNet/DataAcquisition/Dockerfile
    networks:
      - link-nw
    depends_on:
      - kafka_init
      - otel-collector
      - mssql_init
      - loki

  demo-app:
    image: link-demo-app
    container_name: link-demo-app
    ports:
      - "8066:80"
    build:
      context: Web/DemoApp
    networks:
      - link-nw
    depends_on:
      - kafka_b

  measureeval:
    image: link-measureeval
    container_name: link-measureeval
    environment:
      server.port: 8067
      spring.data.mongodb.uri: mongodb://mongo:27017
      spring.data.mongodb.database: link-measureeval
      spring.kafka.bootstrap-servers: kafka_b:9094
      spring.kafka.consumer.group-id: measureeval-events
      spring.kafka.consumer.client-id: measureeval-client
      spring.kafka.properties.security.protocol: SASL_PLAINTEXT
      spring.kafka.properties.sasl.mechanism: PLAIN
      spring.kafka.properties.sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_CLIENT_USER}" password="${KAFKA_SASL_CLIENT_PASSWORD}";
      spring.security.oauth2.resourceserver.jwt.issuer-uri: https://oauth.nhsnlink.org/realms/NHSNLink
      authentication.anonymous: true
      link.data-acquisition.base-url: http://dataacquisition:8065
      spring_profiles_active: dev
      loki.enabled: false
    ports:
      - "8067:8067"
    build:
      context: Java/
      dockerfile: measureeval/Dockerfile
    networks:
      - link-nw
    depends_on:
      - kafka_init
      - mongo
      - dataacquisition
      
  normalization:
    image: link-normalization
    container_name: link-normalization
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      ServiceInformation__Name: Link Normalization Service
      ServiceInformation__Version: 1.1.00-dev
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      DatabaseProvider: SqlServer
      AutoMigrate: true
      ConnectionStrings__DatabaseConnection: Server=tcp:mssql,1433;Initial Catalog=link-normalization;Persist Security Info=False;User ID=sa;Password=${LINK_DB_PASS};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
      ServiceRegistry__TenantService__TenantServiceURL: http://tenant:8074
      ServiceRegistry__TenantService__CheckIfTenantExists: false
      ServiceRegistry__TenantService__GetTenantRelativeEndpoint: facility/
      EnableSwagger: true
      Authentication__EnableAnonymousAccess: true
    ports:
      - "8068:8068"
    build:
      context: .
      dockerfile: DotNet/Normalization/Dockerfile
    networks:
      - link-nw
    depends_on:
      - kafka_init
      - otel-collector
      - loki
      
  notification:
    image: link-notification
    container_name: link-notification
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      ServiceInformation__Name: Link Notification Service
      ServiceInformation__Version: 1.1.00-dev
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      DatabaseProvider: SqlServer
      AutoMigrate: true
      ConnectionStrings__DatabaseConnection: Server=tcp:mssql,1433;Initial Catalog=link-notification;Persist Security Info=False;User ID=sa;Password=${LINK_DB_PASS};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;
      ServiceRegistry__TenantService__TenantServiceURL: http://tenant:8074
      ServiceRegistry__TenantService__CheckIfTenantExists: false
      ServiceRegistry__TenantService__GetTenantRelativeEndpoint: facility/
      IdentityProviderConfig__Issuer: https://oauth.nhsnlink.org/realms/NHSNLink
      IdentityProviderConfig__Audience: https://oauth.nhsnlink.org/realms/NHSNLink
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
      EnableSwagger: true
      Authentication__EnableAnonymousAccess: true
    ports:
      - "8069:8069"
    build:
      context: .
      dockerfile: DotNet/Notification/Dockerfile
    networks:
      - link-nw
    depends_on:
      - kafka_init
      - otel-collector
      - mssql_init
      - loki
      
  querydispatch:
    image: link-querydispatch
    container_name: link-querydispatch
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      ServiceInformation__Name: Link Query Dispatch Service
      ServiceInformation__Version: 1.1.00-dev
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      DatabaseProvider: SqlServer
      AutoMigrate: true
      ConnectionStrings__DatabaseConnection: Server=tcp:mssql,1433;Initial Catalog=link-querydispatch;Persist Security Info=False;User ID=sa;Password=${LINK_DB_PASS};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
      ServiceRegistry__TenantService__TenantServiceURL: http://tenant:8074
      ServiceRegistry__TenantService__CheckIfTenantExists: false
      ServiceRegistry__TenantService__GetTenantRelativeEndpoint: facility/
      EnableSwagger: true
      Authentication__EnableAnonymousAccess: true
    ports:
      - "8071:8071"
    build:
      context: .
      dockerfile: DotNet/QueryDispatch/Dockerfile
    networks:
      - link-nw
    depends_on:
      - kafka_init
      - otel-collector
      - mongo
      - loki

  report:
    image: link-report
    container_name: link-report
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      ServiceInformation__Name: Link Report Service
      ServiceInformation__Version: 1.1.00-dev
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      MongoDB__ConnectionString: mongodb://mongo:27017
      MongoDB__DatabaseName: link-report
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
      ServiceRegistry__TenantService__TenantServiceUrl: http://tenant:8074
      ServiceRegistry__TenantService__CheckIfTenantExists: false
      ServiceRegistry__TenantService__GetTenantRelativeEndpoint: facility/
      EnableSwagger: true
      Authentication__EnableAnonymousAccess: true
    ports:
      - "8072:8072"
    build:
      context: .
      dockerfile: DotNet/Report/Dockerfile
    networks:
      - link-nw
    depends_on:
      - kafka_init
      - otel-collector
      - mongo
      - loki

  submission:
    image: link-submission
    container_name: link-submission
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      ServiceInformation__Name: Link Submission Service
      ServiceInformation__Version: 1.1.00-dev
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      MongoDB__ConnectionString: mongodb://mongo:27017
      MongoDB__DatabaseName: link-report
      # TODO: Replce with Mongo dependency when LNK-2166 finishes
      # DatabaseProvider: SqlServer
      # AutoMigrate: true
      # ConnectionStrings__DatabaseConnection: Server=tcp:mssql,1433;Initial Catalog=link-submission;Persist Security Info=False;User ID=sa;Password=${LINK_DB_PASS};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;
      SubmissionServiceConfig__ReportServiceUrl: http://report:8072/api/Report
      SubmissionServiceConfig__CensusUrl: http://census:8064/api/Census
      SubmissionServiceConfig__DataAcquisitionUrl: http://dataacquisition:8065/api
      SubmissionServiceConfig__SubmissionDirectory: submissions
      SubmissionServiceConfig__PatientBundleBatchSize: 5
      SubmissionServiceConfig__MeasureNames__0__Url: http://www.cdc.gov/nhsn/fhirportal/dqm/ig/Measure/NHSNdQMAcuteCareHospitalInitialPopulation
      SubmissionServiceConfig__MeasureNames__0__MeasureId: NHSNdQMAcuteCareHospitalInitialPopulation
      SubmissionServiceConfig__MeasureNames__0__ShortName: HYPO
      SubmissionServiceConfig__MeasureNames__1__Url: http://www.cdc.gov/nhsn/fhirportal/dqm/ig/Measure/NHSNGlycemicControlHypoglycemicInitialPopulation
      SubmissionServiceConfig__MeasureNames__1__MeasureId: NHSNGlycemicControlHypoglycemicInitialPopulation
      SubmissionServiceConfig__MeasureNames__1__ShortName: ACH
      SubmissionServiceConfig__MeasureNames__2__Url: http://www.cdc.gov/nhsn/fhirportal/dqm/ig/Measure/NHSNRespiratoryPathogensSurveillanceInitialPopulation
      SubmissionServiceConfig__MeasureNames__2__MeasureId: NHSNRespiratoryPathogensSurveillanceInitialPopulation
      SubmissionServiceConfig__MeasureNames__2__ShortName: RPS
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
      EnableSwagger: true
      Authentication__EnableAnonymousAccess: true
    ports:
      - "8073:8073"
    build:
      context: .
      dockerfile: DotNet/Submission/Dockerfile
    networks:
      - link-nw
    volumes: 
      - submission_data:/data/Submission
    depends_on:
      - kafka_init
      - otel-collector
      - mongo
      #- mssql_init
      - loki


  tenant:
    image: link-tenant
    container_name: link-tenant
    environment:
      ASPNETCORE_ENVIRONMENT: Docker
      ServiceInformation__Name: Link Tenant Service
      ServiceInformation__Version: 1.1.00-dev
      KafkaConnection__BootstrapServers__0: kafka_b:9094
      KafkaConnection__SaslProtocolEnabled: true
      KafkaConnection__SaslUsername: ${KAFKA_SASL_CLIENT_USER}
      KafkaConnection__SaslPassword: ${KAFKA_SASL_CLIENT_PASSWORD}
      DatabaseProvider: SqlServer
      AutoMigrate: true
      ConnectionStrings__DatabaseConnection: Server=tcp:mssql,1433;Initial Catalog=link-tenant;Persist Security Info=False;User ID=sa;Password=${LINK_DB_PASS};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;
      Serilog__WriteTo__0__Args__uri: http://loki:3100
      Telemetry__EnableTelemetry: true
      Telemetry__EnableOtelCollector: true
      Telemetry__OtelCollectorEndpoint: http://otel-collector:4317
      EnableSwagger: true
      Authentication__EnableAnonymousAccess: true
      LinkTokenService__EnableTokenGenerationEndpoint: false
      ServiceRegistry__MeasureServiceUrl: http://measureeval:8067
    ports:
      - "8074:8074"
    build:
      context: .
      dockerfile: DotNet/Tenant/Dockerfile
    networks:
      - link-nw
    depends_on:
      - kafka_init
      - otel-collector
      - loki
      - mssql_init

  validation:
    image: link-validation
    container_name: link-validation
    environment:
      server.port: 8075
      spring.security.oauth2.resourceserver.jwt.issuer-uri: https://oauth.nhsnlink.org/realms/NHSNLink
      spring.datasource.url: jdbc:sqlserver://;serverName=mssql;databaseName=link-validation;encrypt=true;trustServerCertificate=true
      spring.datasource.username: sa
      spring.datasource.password: ${LINK_DB_PASS}
      spring.kafka.bootstrap-servers: kafka_b:9094
      spring.kafka.properties.security.protocol: SASL_PLAINTEXT
      spring.kafka.properties.sasl.mechanism: PLAIN
      spring.kafka.properties.sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_CLIENT_USER}" password="${KAFKA_SASL_CLIENT_PASSWORD}";
      authentication.enableAnonymousAccess: true
      secretManagement.managerUri: https://link-vault.vault.azure.net/
      spring.jpa.hibernate.ddl-auto: update
      authentication.anonymous: true
      spring_profiles_active: dev
      loki.enabled: false
      loki.url: http://loki:3100
    ports:
      - "8075:8075"
    build:
      context: Java/
      dockerfile: validation/Dockerfile
    networks:
      - link-nw
    depends_on:
      - kafka_init
      - mssql_init

networks:
  link-nw:
     
volumes:
  kafka_data:
    driver: local
  mssql_data:
    driver: local
  redis_cache:
    driver: local
  mongo_data:
    driver: local
  submission_data:
    driver: local
